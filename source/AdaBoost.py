# -*- coding: utf-8 -*-
# @Time    : 2018/2/11
# @Author  : yipwinghong
# @Email   : yipwinghong@outlook.com
# @File    : AdaBoost.py
# @Software: PyCharm

"""
    AdaBoost：元算法，关于算法的组合方式，即集成方法（可以是不同算法集成、或同一算法不同设置下集成）
    非均衡分类：正负类样本数目差距很大

    bagging：
        自举汇聚法：原始数据集选择S次后得到S个新数据集，新数据集和原数据集大小相等（有放回抽取）
        将某个学习学习算法分别作用于每个数据集、串行训练得到S个分类器，
        使用S个分类器进行分类，并投票选出最多的类别作为最后的结果
    boosting：
        训练分类器的方式和前面类似，但通过集中关注被已有分类器错分的数据获得新分类器

    优点：泛化错误率低，易编码，可以应在大部分分类器上，无参数调整
    缺点：对离群点敏感
    适用数据类型：数值型和标称型数据


"""

